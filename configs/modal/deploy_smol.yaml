model_id: Qwen/Qwen3-1.7B
model_rev: 0060bc56d46589041c1048efd1a397421b1142b5
target_input_concurrency: 8
max_input_concurrency: 16
vllm_cfg:
deployment_config:
  num_nodes: 1
  gpus_per_node: 1
  gpu_type: H100
timeout: 10800
scaledown_window: 900
deployment_name: openevolve-inference
deployment_tags:
  - openevolve
  - qwen3-1b
  - 1xH100
